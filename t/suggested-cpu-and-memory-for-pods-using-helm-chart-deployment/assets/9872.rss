<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Suggested CPU and Memory for Pods Using Helm Chart Deployment</title>
    <link>https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872</link>
    <description>### Issue Summary

I have deployed Redash using helm (contrib-helm-chart). Are there any suggested values for CPU and memory for each pod? The goal is to support 100 concurrent users.

For example, the &quot;genericworker&quot; pod recommends the values `CPU: 100m, memory: 500Mi ` in the provided helm chart. When using similar values, the worker took a very long time to process queued jobs. It took &quot;genericworker&quot; ~48 hours to process 400,000 jobs before the events table was populated.

I am looking for other recommended values across all pods (server, adhocWorker, scheduledWorker, hookInstallJob, hookUpgradeJob, genericWorker, scheduler) that have worked well for similar helm deployments. Thank you!

### Technical details:

* Redash Version: 10.1.0
* Browser/OS: chrome v97.0.4692.71 / macos v11.6.2
* How did you install Redash: contrib-helm-chart</description>
    
    <lastBuildDate>Tue, 01 Feb 2022 15:29:21 +0000</lastBuildDate>
    <category>Self Hosted Redash Support</category>
    <atom:link href="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Suggested CPU and Memory for Pods Using Helm Chart Deployment</title>
        <dc:creator><![CDATA[jesse]]></dc:creator>
        <description><![CDATA[
            <p>You should ask this question of the helm_chart maintainers. It’s not part of the core team so we don’t have any information about it.</p>
          <p><a href="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/5">Read full topic</a></p>
        ]]></description>
        <link>https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/5</link>
        <pubDate>Tue, 01 Feb 2022 15:29:21 +0000</pubDate>
        <guid isPermaLink="false">discuss.redash.io-post-9872-5</guid>
        <source url="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872.rss">Suggested CPU and Memory for Pods Using Helm Chart Deployment</source>
      </item>
      <item>
        <title>Suggested CPU and Memory for Pods Using Helm Chart Deployment</title>
        <dc:creator><![CDATA[mains]]></dc:creator>
        <description><![CDATA[
            <p>Does the helm chart have built in methods for autoscaling pods? I am interested in using horizontal pod autoscaling on the pods themselves, and manually provisioning a certain <code>WORKER_COUNT</code> per pod.</p>
          <p><a href="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/4">Read full topic</a></p>
        ]]></description>
        <link>https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/4</link>
        <pubDate>Fri, 28 Jan 2022 21:04:25 +0000</pubDate>
        <guid isPermaLink="false">discuss.redash.io-post-9872-4</guid>
        <source url="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872.rss">Suggested CPU and Memory for Pods Using Helm Chart Deployment</source>
      </item>
      <item>
        <title>Suggested CPU and Memory for Pods Using Helm Chart Deployment</title>
        <dc:creator><![CDATA[jesse]]></dc:creator>
        <description><![CDATA[
            <p>There are no suggested values because every workload is different. We’d recommend going by trial-and-error as it is quite easy to adjust these values.</p>
          <p><a href="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/3">Read full topic</a></p>
        ]]></description>
        <link>https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/3</link>
        <pubDate>Fri, 28 Jan 2022 17:36:07 +0000</pubDate>
        <guid isPermaLink="false">discuss.redash.io-post-9872-3</guid>
        <source url="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872.rss">Suggested CPU and Memory for Pods Using Helm Chart Deployment</source>
      </item>
      <item>
        <title>Suggested CPU and Memory for Pods Using Helm Chart Deployment</title>
        <dc:creator><![CDATA[mains]]></dc:creator>
        <description><![CDATA[
            <p>To follow up on this question, when using the contrib-helm-chart deployment, is there a suggested method to determine the optimal <code>WORKERS_COUNT</code> for adhocWorker, scheduledWorker, and genericWorker?</p>
<p>I would like to make sure there are enough workers to prevent queues from being backed up.</p>
          <p><a href="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/2">Read full topic</a></p>
        ]]></description>
        <link>https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/2</link>
        <pubDate>Fri, 28 Jan 2022 15:16:14 +0000</pubDate>
        <guid isPermaLink="false">discuss.redash.io-post-9872-2</guid>
        <source url="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872.rss">Suggested CPU and Memory for Pods Using Helm Chart Deployment</source>
      </item>
      <item>
        <title>Suggested CPU and Memory for Pods Using Helm Chart Deployment</title>
        <dc:creator><![CDATA[mains]]></dc:creator>
        <description><![CDATA[
            <h3>
<a name="issue-summary-1" class="anchor" href="https://discuss.redash.io#issue-summary-1"></a>Issue Summary</h3>
<p>I have deployed Redash using helm (contrib-helm-chart). Are there any suggested values for CPU and memory for each pod? The goal is to support 100 concurrent users.</p>
<p>For example, the “genericworker” pod recommends the values <code>CPU: 100m, memory: 500Mi </code> in the provided helm chart. When using similar values, the worker took a very long time to process queued jobs. It took “genericworker” ~48 hours to process 400,000 jobs before the events table was populated.</p>
<p>I am looking for other recommended values across all pods (server, adhocWorker, scheduledWorker, hookInstallJob, hookUpgradeJob, genericWorker, scheduler) that have worked well for similar helm deployments. Thank you!</p>
<h3>
<a name="technical-details-2" class="anchor" href="https://discuss.redash.io#technical-details-2"></a>Technical details:</h3>
<ul>
<li>Redash Version: 10.1.0</li>
<li>Browser/OS: chrome v97.0.4692.71 / macos v11.6.2</li>
<li>How did you install Redash: contrib-helm-chart</li>
</ul>
          <p><a href="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/1">Read full topic</a></p>
        ]]></description>
        <link>https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872/1</link>
        <pubDate>Tue, 18 Jan 2022 22:19:39 +0000</pubDate>
        <guid isPermaLink="false">discuss.redash.io-post-9872-1</guid>
        <source url="https://discuss.redash.io/t/suggested-cpu-and-memory-for-pods-using-helm-chart-deployment/9872.rss">Suggested CPU and Memory for Pods Using Helm Chart Deployment</source>
      </item>
  </channel>
</rss>
