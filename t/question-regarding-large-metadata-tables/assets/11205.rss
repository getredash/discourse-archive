<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Question regarding large metadata tables</title>
    <link>https://discuss.redash.io/t/question-regarding-large-metadata-tables/11205</link>
    <description>Hey! I&#39;m an engineer on team that provides Redash as a service for over 100 customers! We&#39;re appreciative of the open source model and have made some changes to fit our use cases. One such change is the retention of the unused query results in the query_results metadata table. We want to perform analytics on the queries that our customers are writing and identify most used tables, columns and least used tables, columns. As such, we&#39;ve modified the delete in the maintenance.py file to update the &#39;data&#39; column to an empty string (since the actual query results are irrelevant) instead of deleting the unused queries. 

I&#39;ve seen topics here that mentioned issues with large query_results tables but my question is that can a large metadata table affect performance of Redash for our customers? I realize there are inserts to that table every time a query is run by customers but I wanted to make sure that customers do not face any issues with this change.</description>
    
    <lastBuildDate>Tue, 25 Oct 2022 18:58:55 +0000</lastBuildDate>
    <category>Usage Support</category>
    <atom:link href="https://discuss.redash.io/t/question-regarding-large-metadata-tables/11205.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Question regarding large metadata tables</title>
        <dc:creator><![CDATA[dataengineerno1000]]></dc:creator>
        <description><![CDATA[
            <p>Hey! I’m an engineer on team that provides Redash as a service for over 100 customers! We’re appreciative of the open source model and have made some changes to fit our use cases. One such change is the retention of the unused query results in the query_results metadata table. We want to perform analytics on the queries that our customers are writing and identify most used tables, columns and least used tables, columns. As such, we’ve modified the delete in the maintenance.py file to update the ‘data’ column to an empty string (since the actual query results are irrelevant) instead of deleting the unused queries.</p>
<p>I’ve seen topics here that mentioned issues with large query_results tables but my question is that can a large metadata table affect performance of Redash for our customers? I realize there are inserts to that table every time a query is run by customers but I wanted to make sure that customers do not face any issues with this change.</p>
          <p><a href="https://discuss.redash.io/t/question-regarding-large-metadata-tables/11205/1">Read full topic</a></p>
        ]]></description>
        <link>https://discuss.redash.io/t/question-regarding-large-metadata-tables/11205/1</link>
        <pubDate>Tue, 25 Oct 2022 18:58:55 +0000</pubDate>
        <guid isPermaLink="false">discuss.redash.io-post-11205-1</guid>
        <source url="https://discuss.redash.io/t/question-regarding-large-metadata-tables/11205.rss">Question regarding large metadata tables</source>
      </item>
  </channel>
</rss>
